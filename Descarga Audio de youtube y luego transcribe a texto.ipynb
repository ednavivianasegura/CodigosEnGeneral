{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc712f7",
      "metadata": {
        "id": "3bc712f7"
      },
      "outputs": [],
      "source": [
        "# !pip install jupyter\n",
        "# # To install required libraries:\n",
        "# !pip install google-api-python-client\n",
        "# !pip install pytube\n",
        "# !pip install git+https://github.com/openai/whisper.git\n",
        "# !pip install jiwer\n",
        "# # !pip install whisper\n",
        "# !pip install googletrans==3.1.0a0\n",
        "# !pip install selenium\n",
        "# !pip install simplified-scrapy\n",
        "# # !pip install googletrans\n",
        "# !pip install imageio==2.4.1\n",
        "# !pip install sinfo\n",
        "# !pip install pandas\n",
        "# !pip install pymongo\n",
        "# !pip install dnspython==2.3.0\n",
        "# !pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd /content/drive/My Drive/\n",
        "\n",
        "# os.chdir('/content/drive/MyDrive/Colab Notebooks/RedesSociales/Youtube/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O427TIME0zf",
        "outputId": "c1b034ca-4fa9-468d-af22-eee1e0397da6"
      },
      "id": "6O427TIME0zf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e47944ac",
      "metadata": {
        "id": "e47944ac"
      },
      "outputs": [],
      "source": [
        "# from googleapiclient.discovery import build\n",
        "# from datetime import datetime\n",
        "# import pandas as pd\n",
        "# from pytube import YouTube\n",
        "# import pymongo as mon\n",
        "# import whisper\n",
        "# import os\n",
        "# import time\n",
        "# import json\n",
        "# # import funciones_scraping as funciones\n",
        "# # #Traducción con google\n",
        "# from googletrans import Translator\n",
        "# translator = Translator()\n",
        "\n",
        "# from IPython.display import HTML, Audio\n",
        "# # from google.colab.output import eval_js\n",
        "# #from base64 import b64decode\n",
        "# #import numpy as np\n",
        "# #from scipy.io.wavfile import read as wav_read\n",
        "# #import io\n",
        "# #import ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e613b7a",
      "metadata": {
        "id": "0e613b7a"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     with open('YoutubeInputs.txt', 'r') as jsonfile:\n",
        "#         jsondata = ''.join(line for line in jsonfile if not line.startswith('#'))\n",
        "#         YoutubeInputs = json.loads(jsondata)\n",
        "# except:\n",
        "#     exit(\"The input values could not be read correctly.\")\n",
        "\n",
        "# api_key     = YoutubeInputs[\"api_key\"]\n",
        "# MONGO_URI   = YoutubeInputs[\"MONGO_URI\"]\n",
        "# MaxDuration = YoutubeInputs[\"MaxDuration\"]\n",
        "\n",
        "#en la web:https://commentpicker.com/youtube-channel-id.php se puede extraer el Channel Id de una url de youtube\n",
        "\n",
        "# channel_ids = [\n",
        "#                'UCT9cdv7iczZh30z0ThdEvgg', # \"MONDRAGON Corporation\"\n",
        "#                'UChn9nH2YhcGIWCunj22nk4A', # \"ORBEA\"\n",
        "#                'UCQCCtBEQ4dc1QNOaIcZ1hhQ', #\"Grupo ULMA\"\n",
        "#                'UCR2hArKzdqQh0wmG_vCatkw' ,#\"ULMA Construction\"\n",
        "#                'UCJseN-6UnlZ0kMXJB-dVFJg' #Proyecto Bellota\n",
        "#               ]\n",
        "# autores=[\n",
        "#          \"MONDRAGON Corporation\",\n",
        "#          \"ORBEA\",\n",
        "#          \"Grupo ULMA\",\n",
        "#          \"ULMA Construction\",\n",
        "#          \"Proyecto Bellota\"\n",
        "# ]\n",
        "# youtube = build('youtube', 'v3', developerKey=api_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66eeaff7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66eeaff7",
        "outputId": "aca1da52-a260-485f-e424-e0ed6c0b9d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coneccion a mongo exitosa\n"
          ]
        }
      ],
      "source": [
        "# MONGO_TIEMPO_FUERA=500\n",
        "# try:\n",
        "#     cliente=mon.MongoClient(MONGO_URI,serverSelectionTimeoutMS=MONGO_TIEMPO_FUERA)\n",
        "#     print(\"Coneccion a mongo exitosa\")\n",
        "# except mon.errors.ServerSelectionTimeoutError as errorTiempo:\n",
        "#     cliente=\"\"\n",
        "#     print(f\"Tiempo exedido {errorTiempo}\")\n",
        "# except mon.errors.ConnectionFailure as errorConexion:\n",
        "#     cliente=\"\"\n",
        "#     print(f\"Fallo al conectarse a mongodb {errorConexion}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e482215",
      "metadata": {
        "id": "2e482215"
      },
      "outputs": [],
      "source": [
        "# mydb                         = cliente[\"redes_sociales\"]\n",
        "# post_information             = mydb[\"post_information\"]\n",
        "# autor_information            = mydb[\"autor_information\"]\n",
        "\n",
        "# PathTextExtraction=\"audio_transcriptionYT/\"\n",
        "# try:\n",
        "#   os.stat(PathTextExtraction)\n",
        "# except:\n",
        "#   os.mkdir(PathTextExtraction)\n",
        "# #Cargar modelo para extraer texto\n",
        "# model = whisper.load_model(\"medium\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "060f1006",
      "metadata": {
        "id": "060f1006"
      },
      "outputs": [],
      "source": [
        "# def get_videos_information(PathTextExtraction,model,post_information,autor_information,channel_id, MaxDuration,autores):\n",
        "#     mydoc = list(autor_information.find())\n",
        "#     def get_id(item):\n",
        "#       try:\n",
        "#           return item['ID']\n",
        "#       except KeyError:\n",
        "#           return None\n",
        "\n",
        "#     IDS = [get_id(mydoc[i]) for i in range(len(mydoc)) if get_id(mydoc[i]) is not None]\n",
        "#     channel_statistics = funciones.get_channel_stats(youtube, channel_id)[0]\n",
        "\n",
        "#     for i in range(len(channel_statistics)):\n",
        "#         channel_statistics[i][\"Autor\"]=autores[i]\n",
        "\n",
        "#     nChannels=len(channel_statistics)\n",
        "#     print(f\"Número de Channels: {nChannels}\")\n",
        "\n",
        "#     for channel in channel_statistics:\n",
        "#         # channel['name'] = channel['Channel_name'].replace(\" \",\"\")\n",
        "#         channel['name'] = channel['Autor'].replace(\" \",\"_\")\n",
        "#         channel.pop('Channel_name')\n",
        "#         channel['UploadDate']=datetime.now()\n",
        "#         id=channel['ID']\n",
        "#         channel[\"source\"]=\"youtube\"\n",
        "#         if id not in IDS:\n",
        "#             print(f\"Insertar:\\nDocumento con ID: {id}\")\n",
        "#             funciones.insert_document(autor_information,channel)\n",
        "#         else:\n",
        "#             myquery = {\"ID\": id}\n",
        "#             mydoc = autor_information.find(myquery)\n",
        "#             q_Liest=list(mydoc)\n",
        "#             q_Liest[0].pop('_id')\n",
        "#             q_Liest[0].pop('UploadDate')\n",
        "#             channel2=channel.copy()\n",
        "#             channel2.pop('UploadDate')\n",
        "#             if not channel2==q_Liest[0]:\n",
        "#                 print(f\"Actualizar:\\nDocumento con ID: {id}\")\n",
        "#                 oldvalues = list(autor_information.find(myquery))[0]\n",
        "#                 newvalues = {\"$set\": channel}\n",
        "#             ##########################################################\n",
        "#                 # Update collection\n",
        "#                 funciones.update_document(autor_information,oldvalues,newvalues)\n",
        "#     #########################################################################\n",
        "#     #########################################################################\n",
        "#     #########################################################################\n",
        "#     channel_data = pd.DataFrame(channel_statistics)\n",
        "#     video_ids=[funciones.get_video_ids(youtube, channel_data.loc[i,\"playlist_id\"]) for i in range(channel_data.shape[0])]\n",
        "\n",
        "#     filesHere=os.listdir(PathTextExtraction)\n",
        "#     for f in filesHere:\n",
        "#         try:\n",
        "#             os.remove(PathTextExtraction+f)\n",
        "#         except:\n",
        "#             print(\"No se puede eliminar\")\n",
        "\n",
        "#     for i in range(len(video_ids)):\n",
        "#         videos = video_ids[i]\n",
        "#         details = funciones.get_video_details(youtube, video_ids[i])\n",
        "#         long=len(videos)\n",
        "#         for v in range(long):\n",
        "#             videoID=videos[v]\n",
        "#             v_details=details[v]\n",
        "#             name   = channel_data.loc[i,\"name\"]\n",
        "#             Autor  = channel_data.loc[i,\"Autor\"]\n",
        "#             IDCha  = channel_data.loc[i, \"ID\"]\n",
        "\n",
        "#             meta = {    \"Autor\"        : Autor,\n",
        "#                         'name'         : name,\n",
        "#                         'ID'           : videoID,\n",
        "#                         'UploadDate'   : datetime.now(),\n",
        "#                         \"source\"       : \"youtube\",\n",
        "#                         \"IDCha\"        : IDCha\n",
        "#                             }\n",
        "#             meta.update(v_details)\n",
        "\n",
        "#             myquery = {'ID': videoID}\n",
        "#             mydoc   = post_information.find(myquery)\n",
        "#             q_Liest = list(mydoc)\n",
        "#             if len(q_Liest)==0:\n",
        "#                 video_link = \"https://www.youtube.com/watch?v=\"+videoID\n",
        "#                 video = YouTube(video_link)\n",
        "#                 try:\n",
        "#                   audio = video.streams.filter(only_audio=True).first().download(PathTextExtraction)\n",
        "#                 except:\n",
        "#                   break\n",
        "#                 lenght_of_video= video.length\n",
        "#                 meta[\"lenght_of_video\"]= lenght_of_video\n",
        "#                 meta[\"MaxDuration\"]  = MaxDuration\n",
        "#                 if lenght_of_video<=MaxDuration:\n",
        "#                     print(f\"The duration of the video is {lenght_of_video} seconds\")\n",
        "#                     Inicio=time.time()\n",
        "#                     result= model.transcribe(audio)\n",
        "#                     Fin1=time.time()\n",
        "#                     Texto=result[\"text\"]\n",
        "#                     print(f\"Text extraction time: {Fin1-Inicio}\\n\")\n",
        "#                 try:\n",
        "#                     meta['TextVideo']         = Texto\n",
        "#                 except:\n",
        "#                     meta[\"TextVideo\"]         = \"\"\n",
        "#                 try:\n",
        "#                     meta['TextVideoEn']       = translator.translate(str(Texto), dest='en').text\n",
        "#                 except:\n",
        "#                     meta['TextVideoEn']       = \"\"\n",
        "\n",
        "#                 funciones.insert_document(post_information,meta)\n",
        "\n",
        "#             else:\n",
        "#                 print(\"Si existe el id\")\n",
        "#                 q_Liest[0].pop('_id')\n",
        "#                 q_Liest[0].pop('UploadDate')\n",
        "\n",
        "#                 meta2=meta.copy()\n",
        "#                 meta2.pop('UploadDate')\n",
        "#                 if not meta2==q_Liest[0]:\n",
        "#                     print(\"No son iguales\")\n",
        "#                     print(f\"Actualizar:\\nDocumento con ID: {videoID}\")\n",
        "\n",
        "#                     oldvalues = list(post_information.find(myquery))[0]\n",
        "#                     newvalues = { \"$set\": meta}\n",
        "#                     ##########################################################\n",
        "#                      # Update collection\n",
        "#                     funciones.update_document(post_information,oldvalues,newvalues)\n",
        "#                     ##########################################################\n",
        "#                 else:\n",
        "#                     print(f\"The document already exists and has not been updated to date.\")\n",
        "\n",
        "#     #\n",
        "#     filesHere=os.listdir(PathTextExtraction)\n",
        "#     for f in filesHere:\n",
        "#         try:\n",
        "#             os.remove(PathTextExtraction+f)\n",
        "#         except:\n",
        "#             print(\"No se puede eliminar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1237a3",
      "metadata": {
        "id": "de1237a3"
      },
      "outputs": [],
      "source": [
        "# for ci, ai in zip(channel_ids,autores):\n",
        "#     print(f\"Autor: {ai}\")\n",
        "#     get_videos_information(PathTextExtraction,model,post_information,autor_information,[ci], MaxDuration,[ai])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pytube import YouTube\n",
        "\n",
        "# # URL del video de YouTube\n",
        "# url = \"https://www.youtube.com/watch?v=Lk-K9ftWUuw&ab_channel=AprendeIAconLigdiGonzalez\"\n",
        "\n",
        "# try:\n",
        "#     # Crear un objeto YouTube con la URL\n",
        "#     yt = YouTube(url)\n",
        "\n",
        "#     # Obtener la mejor resolución disponible\n",
        "#     video = yt.streams.get_highest_resolution()\n",
        "\n",
        "#     # Descargar el video\n",
        "#     video.download(PathTextExtraction)\n",
        "\n",
        "#     print(\"Video descargado exitosamente como:\", video.default_filename)\n",
        "\n",
        "# except Exception as e:\n",
        "#     print(\"Ocurrió un error al descargar el video:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJmPRSf5XrZ8",
        "outputId": "b064eb06-a673-42bd-f9ae-851052c9fd72"
      },
      "id": "EJmPRSf5XrZ8",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video descargado exitosamente como: ¿QUÉ ES EL PROCESAMIENTO DEL LENGUAJE NATURAL  06 Inteligencia Artificial 101  AprendeIA.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "from pytube import YouTube"
      ],
      "metadata": {
        "id": "Ug7plA1efbCT"
      },
      "id": "Ug7plA1efbCT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PathTextExtraction=\"audio_transcriptionYT/\"\n",
        "try:\n",
        "  os.stat(PathTextExtraction)\n",
        "except:\n",
        "  os.mkdir(PathTextExtraction)\n",
        "#Cargar modelo para extraer texto\n",
        "model = whisper.load_model(\"medium\")"
      ],
      "metadata": {
        "id": "Ih7c-xYPfWQr"
      },
      "id": "Ih7c-xYPfWQr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_link = \"https://www.youtube.com/watch?v=Lk-K9ftWUuw&ab_channel=AprendeIAconLigdiGonzalez\"\n",
        "video = YouTube(video_link)"
      ],
      "metadata": {
        "id": "v1kivvO6eSyO"
      },
      "id": "v1kivvO6eSyO",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pasar video a audio\n",
        "audio = video.streams.filter(only_audio=True).first().download(PathTextExtraction)"
      ],
      "metadata": {
        "id": "xQZaTdQOdsBb"
      },
      "id": "xQZaTdQOdsBb",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result= model.transcribe(audio)\n",
        "Texto=result[\"text\"]"
      ],
      "metadata": {
        "id": "-qROX3eWejVc"
      },
      "id": "-qROX3eWejVc",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Texto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "NQC42FjqeqzE",
        "outputId": "82f044bd-90f4-495f-e0af-6568ebdee7b2"
      },
      "id": "NQC42FjqeqzE",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hola a todos y bienvenidos a un nuevo video en el canal, en este video te explicaré de qué se trata el procesamiento de lenguaje natural, por lo tanto empecemos con el video. Todo lo que expresamos ya sea verbalmente o por escrito, conlleva enormes cantidades de información. El tema que elegimos, nuestro tono, nuestra selección de palabras, todo añade algún tipo de información que se puede interpretar y extraer valor de ella. En teoría, podemos entender e incluido predecir el comportamiento humano utilizando esa información. Pero hay un problema, una persona puede generar cientos o miles de palabras en una declaración y en cada frase tiene su correspondiente complejidad. Los datos generados a partir de conversaciones, declaraciones o inclusive tweets son ejemplos de datos no estructurados. Los datos no estructurados no encajan perfectamente en la estructura tradicional de filas y columnas de las bases de datos relacionales y representan la gran mayoría de datos disponibles en el mundo real. Son desordenados y difíciles de manipular, sin embargo, gracias a los avances en disciplinas como Machine Learning, se está produciendo una gran revolución de este tema. Hoy en día ya no se trata de intentar interpretar un texto o discurso a partir de sus palabras, la antigua forma mecánica, sino de entender el significado que hay detrás de esas palabras, la forma cognitiva. De esta manera es posible detectar figuras del lenguaje como la ironía o incluso realizar un análisis de sentimientos. ¿Qué es el procesamiento del lenguaje natural? El procesamiento del lenguaje natural es la rama de la informática y más específicamente de la Inteligencia Artificial que se ocupa de dotar a los computadores de la capacidad de entender textos y palabras habladas de forma muy similar a la de los seres humanos. El procesamiento del lenguaje natural combina la lingüística computacional, el modelado del lenguaje humano basado en reglas con modelos estadísticos de Machine Learning y de Deep Learning. Juntas, estas tecnologías permiten a las computadoras procesar el lenguaje humano en forma de texto o datos de voz y entender su significado completo, con la intención y el sentimiento del hablante o escritor. ¿Cómo funciona el procesamiento del lenguaje natural? El lenguaje humano está repleto de ambiguidades que hacen increíblemente difícil escribir un software que determine con precisión el significado deseado de los datos de texto o de voz. Por lo tanto, el procesamiento del lenguaje natural permite a las computadoras entender el lenguaje natural como lo hacen los humanos, tanto si el lenguaje es hablado como escrito. El procesamiento del lenguaje natural utiliza la Inteligencia Artificial para tomar datos del mundo real, procesarlos y darles un sentido que el computador pueda entender. Al igual que los humanos tienen diferentes sensores como los oídos para oír y los ojos para ver, las computadoras tienen programas para leer y micrófonos para recoger el audio, y al igual que los humanos tienen cerebro para procesar esa entrada, las computadoras tienen un programa para procesar sus respectivas entradas. En algún momento del procesamiento, la entrada se convierte en un código que el computador puede entender. El procesamiento del lenguaje natural consta de dos fases principales, el procesamiento de datos y el desarrollo de algoritmos. El preprocesamiento de datos consiste en preparar y limpiar los datos de texto para puedan analizarlos. El procesamiento pone los datos de forma visible y destaca las características del texto con las que puede trabajar un algoritmo. Hay varias formas de hacerlo, entre ellas tokenización, se trata de dividir el texto en unidades más pequeñas con las que trabajar. Eliminación de las palabras de parada, en este caso se eliminan las palabras comunes del texto para que queden las palabras únicas que ofrecen más información sobre el texto. Lematización y stymie, en este caso las palabras se reducen a sus raíz para poder procesarlas. Etiquetado de parte del discurso, es cuando las palabras se marcan en función de la parte del discurso que son como sustantivos, verbos y adjetivos. Una vez procesados los datos, se desarrolla un algoritmo para procesarlos. Hay muchos algoritmos diferentes del procesamiento del lenguaje natural, pero se suelen utilizar dos tipos principales. Sistema basado en reglas, este sistema utiliza reglas lingüísticas cuidadosamente diseñadas, este enfoque se utilizó al principio del desarrollo del procesamiento en lenguaje natural y todavía se utiliza. Sistema basado en Machine Learning, los algoritmos de Machine Learning utilizan métodos estadísticos, aprenden a realizar tareas basándose en los datos de entrenamiento que reciben y ajustan sus métodos a medida que se procesan más datos. Mediante una combinación de Machine Learning, Deep Learning y redes neuronales, los algoritmos de procesamiento del lenguaje natural perfeccionan sus propias reglas a través del procesamiento y el aprendizaje repetitivo. ¿En dónde se utiliza el procesamiento del lenguaje natural? El procesamiento del lenguaje natural es el motor de la inteligencia artificial en muchas aplicaciones modernas del mundo real. A continuación te dejo varios ejemplos. Detección de spam Es posible que no pienses en la detección de spam como la solución del procesamiento del lenguaje natural, pero las mejores tecnologías de detección de spam utilizan las capacidades de clasificación de texto de procesamiento del lenguaje natural para escanear los correos electrónicos en busca del lenguaje que suele indicar spam o phishing. Estos indicadores pueden incluir el uso excesivo de términos financieros, la mala gramática característica, el lenguaje amenazante, la urgencia inapropiada, los nombres de empresas mal escritos, etc. La detección de spam es uno de los problemas del procesamiento del lenguaje natural que los expertos consideran mayormente resueltos, aunque en estos momentos pueden argumentar que no se ajusta a tu experiencia con el correo electrónico. Traducción automática Google Translate es una de las tecnologías de procesamiento del lenguaje natural ampliamente disponible. La traducción automática verdaderamente útil implica algo más que la sustitución de palabras de un idioma por otras de otro. Una traducción eficaz tiene que cantar con precisión el significado y el tono de la lengua de entrada y traducirlo a un texto con el mismo significado y el mismo impacto deseado en la lengua de salida. Una buena manera de poner en práctica cualquier herramienta de traducción automática es traducir un texto de una lengua y luego volver al original. Asistentes virtuales o Chatbots Los asistentes virtuales como Siri de Apple y Alexa de Amazon utilizan el reconocimiento de voz para reconocer patrones en los comandos de voz y la generación de lenguaje natural para responder con acciones apropiadas o comentarios útiles. Los Chatbots realizan la misma magia en respuesta a entradas de texto escritas. Los mejores también aprenden a reconocer pistas contextuales sobre las solicitudes humanas y las utilizan para ofrecer respuestas u opciones aún mejores con el tiempo. La siguiente mejora para estas aplicaciones es la respuesta a preguntas. Con la capacidad de responder a nuestras preguntas anticipadas o no, con respuestas relevantes y útiles en sus propias palabras. Análisis del sentimiento en las redes sociales El procesamiento del lenguaje natural se ha convertido en una herramienta empresarial esencial para descubrir los datos ocultos de los canales de las redes sociales. El análisis de sentimientos puede analizar el lenguaje utilizado en las publicaciones de las redes sociales, las respuestas, los comentarios, etcétera, para extraer actitudes y emociones en respuesta a los productos, las promociones y los eventos, información que las empresas pueden utilizar en el diseño de productos, las campañas publicitarias, etcétera. Resumen de textos El resumen de texto utiliza técnicas de procesamiento del lenguaje natural para diferir enormes volúmenes de texto digital y crear resúmenes y sinopsis para índices, bases de datos de investigación o lectores ocupados que no tienen tiempo de leer el texto completo. Las mejores aplicaciones de resumen de texto utilizan el razonamiento semántico y la generación del lenguaje natural para añadir contexto y conclusiones útiles a los resúmenes. ¿Cuáles son los beneficios del procesamiento del lenguaje natural? El principal beneficio del procesamiento del lenguaje natural es que mejora la forma en que los humanos y las computadoras se comunican entre sí. La forma más directa de manipular un computador es a través de código, el lenguaje del computador. Al permitir que las computadoras entiendan el lenguaje humano, la interacción de las computadoras se vuelve mucho más intuitiva para los humanos. Otras ventajas son mayor precisión y eficacia de la documentación, capacidad de hacer automáticamente un resumen legible de un texto original más grande y complejo. Utiliza para asistentes personales como Alexa al permitirles entender la palabra hablada. Permite a una organización utilizar chatbots para la atención al cliente. Facilita la realización de análisis de sentimientos. Proporciona conocimientos avanzados de análisis que antes eran inalcanzables debido al volumen ¿Qué desafío presenta el procesamiento del lenguaje natural? El procesamiento del lenguaje natural presenta una serie de retos, la mayoría de los cuales se reducen al hecho de que el lenguaje natural está en constante evolución y siempre es algo ambigüo, entre ellos se encuentra precisión. Tradicionalmente, las computadoras requieren que los humanos les hablen en un lenguaje de programación preciso, sin ambigüedades y muy estructurado mediante un número limitado de órdenes claramente enunciadas. Sin embargo, el habla humana no siempre es precisa, a menudo es ambigua y la estructura lingüística puede depender de muchas variables complejas como la jerga, los dialectos regionales y el contexto social. Tono de voz e inflexión El procesamiento del lenguaje natural aún no se ha perfeccionado, por ejemplo, el análisis semántico puede seguir siendo un reto. Otras dificultades son el hecho de que el uso abstracto del lenguaje suele ser difícil de entender para los programas. Por ejemplo, el procesamiento del lenguaje natural no capta fácilmente el sarcasmo, estos temas suelen requerir la compresión de las palabras que se utilizan y su contexto en una conversación. Otro ejemplo es una frase que puede cambiar de significado dependiendo de la palabra o sílaba en la que el hablante ponga el acento. Los algoritmos de procesamiento del lenguaje natural pueden pasar por alto los sutiles pero importantes cambios de tono en la voz de una persona al realizar el reconocimiento del habla. El tono y la inflexión del habla también pueden variar entre diferentes acentos, lo que puede ser un reto para un algoritmo. Evolución del uso del lenguaje El procesamiento del lenguaje natural también se ve afectado por el hecho de que el lenguaje y la forma en que lo utilizan las personas cambia continuamente. Aunque hay reglas para el lenguaje, ninguna está escrito en piedra y está sujeta a cambios con el tiempo. Las reglas computacionales que funcionan ahora pueden quedar obsoletas cuando las características del lenguaje del mundo real cambien con el tiempo. El procesamiento del lenguaje natural desempeña un papel fundamental en la tecnología y en la forma en que los seres humanos interactúan con ella. Se utiliza en muchas aplicaciones del mundo real, tanto en el ámbito empresarial como en el de los consumidores, como los chatbots, la cyber seguridad, los motores de búsqueda y el análisis de grandes datos. Aunque no está exenta de desafíos, se espera que el procesamiento del lenguaje natural siga siendo una parte importante tanto de la industria como la vida cotidiana. Con esto finalizamos la explicación. Si quieres aprender más sobre inteligencia artificial puedes visitar nuestra página web AprendeIA en donde encontrarás más información como también ebooks y cursos que pueden ayudarte en tu aprendizaje. El link lo encuentras en la cajita de información debajo de este video. Y por supuesto te dejo la pregunta del video, ¿Cuáles de las siguientes afirmaciones crees tú que sea cierta? Opción 1. El procesamiento del lenguaje natural permite a las computadoras entender el lenguaje natural como lo hacen los humanos. Opción 2. El procesamiento del lenguaje natural consta de dos fases principales, el preprocesamiento de datos y el desarrollo de algoritmos. Opción 3. El principal beneficio del procesamiento del lenguaje natural es que mejora la forma en que los humanos y las computadoras se comunican entre sí. Deja en los comentarios cuál crees que es la respuesta correcta, puede ser una o más las respuestas correctas. También te recomiendo que nos sigas en nuestras otras redes sociales en donde publicamos mucha más información de lo que tenemos publicado acá. Todos los links se encuentran en la cajita de información de este video. No te olvides de suscribirte al canal ya que semanalmente encontrarás un nuevo video sobre algún tema relacionado a la inteligencia artificial. Solamente tienes que presionar el botón rojo debajo de este video. Nos vemos en el siguiente video. Chao.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}