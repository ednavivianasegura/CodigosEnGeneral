{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ednavivianasegura/CodigosEnGeneral/blob/main/Descarga%20Audio%20de%20youtube%20y%20luego%20transcribe%20a%20texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código para extraer el audio y el texto de un video de Youtube o de audio cargado\n",
        "\n",
        "Cómo resultado, se extrae un archivo llamado cuyo nombre debe ser proporcionado en la variable **nombre_archivo** que debe ser posteriormente descargado al ordenador local"
      ],
      "metadata": {
        "id": "IM8tzR1XRW_I"
      },
      "id": "IM8tzR1XRW_I"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "xfvEL2HKhPLP",
        "outputId": "2316a13a-738e-41f5-b1f0-3175aac4e0c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xfvEL2HKhPLP",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-tz29qawe\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-tz29qawe\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=72bcf43a64c4c5cf7fbd0d6564c2c2d730288b7fdab7742af6da957a99f8ae00\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-foj40yqd/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20231117 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "from pytube import YouTube"
      ],
      "metadata": {
        "id": "Ug7plA1efbCT"
      },
      "id": "Ug7plA1efbCT",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PathTextExtraction=\"audio_transcriptionYT/\"\n",
        "try:\n",
        "  os.stat(PathTextExtraction)\n",
        "except:\n",
        "  os.mkdir(PathTextExtraction)\n",
        "#Cargar modelo para extraer texto\n",
        "model = whisper.load_model(\"medium\")"
      ],
      "metadata": {
        "id": "Ih7c-xYPfWQr",
        "outputId": "86e09a59-dee8-4e23-b465-9eb257c32f39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ih7c-xYPfWQr",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:13<00:00, 110MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "Si el texto proviene de un video de youtube\n",
        "***"
      ],
      "metadata": {
        "id": "GJO_Stx1PUhP"
      },
      "id": "GJO_Stx1PUhP"
    },
    {
      "cell_type": "code",
      "source": [
        "video_link = \"https://www.youtube.com/watch?v=tQh29_Noo9w&t=18s&ab_channel=Matem%C3%A1ticasprofeAlex\"\n",
        "video = YouTube(video_link)"
      ],
      "metadata": {
        "id": "v1kivvO6eSyO"
      },
      "id": "v1kivvO6eSyO",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pasar video a audio\n",
        "audio = video.streams.filter(only_audio=True).first().download(PathTextExtraction)\n"
      ],
      "metadata": {
        "id": "xQZaTdQOdsBb"
      },
      "id": "xQZaTdQOdsBb",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result= model.transcribe(audio)\n",
        "Texto=result[\"text\"]"
      ],
      "metadata": {
        "id": "-qROX3eWejVc"
      },
      "id": "-qROX3eWejVc",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre del archivo en el que se guardará el texto\n",
        "nombre_archivo = \"texto_del archivo.txt\"\n",
        "\n",
        "# Abrir el archivo en modo escritura ('w')\n",
        "with open(nombre_archivo, 'w') as archivo:\n",
        "    # Escribir el contenido de la variable Texto en el archivo\n",
        "    archivo.write(Texto)"
      ],
      "metadata": {
        "id": "wEwNffUCidBf"
      },
      "id": "wEwNffUCidBf",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "Si el texto proviene de un archivo de audio (Que debe ser cargado en la carpeta **audio_transcriptionYT**)\n",
        "***\n",
        "\n",
        "Es necesario, primero cargar el archivo.mp3 a la carpeta audio_transcriptionYT\n",
        "***"
      ],
      "metadata": {
        "id": "eFE89ziqPgul"
      },
      "id": "eFE89ziqPgul"
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"/content/audio_transcriptionYT/cambridge-english-first-2015-sample-paper-1-listening-audio-file v2.mp3\")\n",
        "Texto=result[\"text\"]\n",
        "nombre_archivo1 = \"Listening_1.txt\"\n",
        "\n",
        "# Abrir el archivo en modo escritura ('w')\n",
        "with open(nombre_archivo1, 'w') as archivo:\n",
        "    # Escribir el contenido de la variable Texto en el archivo\n",
        "    archivo.write(Texto)"
      ],
      "metadata": {
        "id": "6HQ810bgNCkn"
      },
      "id": "6HQ810bgNCkn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}